"""
M칩dulo de An치lise de Cl칤max
Combina an치lise sem칙ntica (palavras-chave) e ac칰stica (volume/energia) para identificar momentos relevantes
"""

import logging
from typing import List, Dict, Tuple, Optional
import numpy as np
import librosa
from pydub import AudioSegment
from pydub.silence import detect_nonsilent

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ClimaxAnalyzer:
    """
    Identifica pontos de cl칤max em v칤deos combinando:
    - An치lise sem칙ntica: palavras-chave na transcri칞칚o
    - An치lise ac칰stica: picos de volume, mudan칞as de energia
    """
    
    def __init__(
        self,
        keywords_climax: List[str],
        keywords_ignore: List[str] = None,
        min_volume_db: float = -10.0,
        cut_duration_min: int = 30,
        cut_duration_max: int = 90,
        pre_roll: int = 5,
        post_roll: int = 5
    ):
        """
        Args:
            keywords_climax: Palavras que indicam momentos interessantes
            keywords_ignore: Palavras que indicam trechos a evitar (patrocinador, etc)
            min_volume_db: Volume m칤nimo para considerar "euforia" (ex: -10db)
            cut_duration_min: Dura칞칚o m칤nima do corte (segundos)
            cut_duration_max: Dura칞칚o m치xima do corte (segundos)
            pre_roll: Segundos antes do ponto de interesse (contexto)
            post_roll: Segundos ap칩s o ponto de interesse (contexto)
        """
        self.keywords_climax = [k.lower() for k in keywords_climax]
        self.keywords_ignore = [k.lower() for k in (keywords_ignore or [])]
        self.min_volume_db = min_volume_db
        self.cut_duration_min = cut_duration_min
        self.cut_duration_max = cut_duration_max
        self.pre_roll = pre_roll
        self.post_roll = post_roll
    
    def analyze_semantic(self, transcription: List[Dict]) -> List[Dict]:
        """
        Analisa a transcri칞칚o buscando palavras-chave de cl칤max
        
        Args:
            transcription: Lista de segmentos da transcri칞칚o
            
        Returns:
            Lista de momentos interessantes encontrados:
            [
                {
                    'type': 'semantic',
                    'keyword': 'milh칚o',
                    'start': 125.5,
                    'end': 130.2,
                    'text': 'Eu ganhei um milh칚o de reais'
                },
                ...
            ]
        """
        climax_moments = []
        
        for segment in transcription:
            text_lower = segment['text'].lower()
            
            # Verificar se cont칠m palavras a ignorar
            should_ignore = any(ignore_word in text_lower for ignore_word in self.keywords_ignore)
            if should_ignore:
                logger.debug(f"Ignorando segmento (palavra de exclus칚o): {segment['text'][:50]}...")
                continue
            
            # Verificar se cont칠m palavras de cl칤max
            for keyword in self.keywords_climax:
                if keyword in text_lower:
                    climax_moments.append({
                        'type': 'semantic',
                        'keyword': keyword,
                        'start': segment['start'],
                        'end': segment['end'],
                        'text': segment['text'],
                        'score': 1.0  # Score base para an치lise sem칙ntica
                    })
                    logger.info(f"Cl칤max sem칙ntico encontrado: '{keyword}' em {segment['start']:.2f}s")
        
        return climax_moments
    
    def analyze_acoustic(self, audio_path: str, sample_window: int = 5) -> List[Dict]:
        """
        Analisa o 치udio buscando picos de volume e energia
        
        Args:
            audio_path: Caminho do arquivo de 치udio
            sample_window: Janela de an치lise em segundos
            
        Returns:
            Lista de momentos com alta energia ac칰stica
        """
        try:
            logger.info(f"Analisando 치udio: {audio_path}")
            
            # Carregar 치udio com librosa
            y, sr = librosa.load(audio_path, sr=None)
            duration = librosa.get_duration(y=y, sr=sr)
            
            # Calcular energia RMS (Root Mean Square) - indica volume
            rms = librosa.feature.rms(y=y)[0]
            
            # Converter RMS para dB
            rms_db = librosa.amplitude_to_db(rms)
            
            # Calcular timestamps para cada frame RMS
            frames = range(len(rms))
            times = librosa.frames_to_time(frames, sr=sr)
            
            # Identificar picos de energia
            climax_moments = []
            threshold_db = self.min_volume_db
            
            for i, (time, db) in enumerate(zip(times, rms_db)):
                if db > threshold_db:
                    # Agrupar picos pr칩ximos
                    start_time = max(0, time - sample_window / 2)
                    end_time = min(duration, time + sample_window / 2)
                    
                    climax_moments.append({
                        'type': 'acoustic',
                        'start': float(start_time),
                        'end': float(end_time),
                        'peak_db': float(db),
                        'score': float((db - threshold_db) / 10)  # Score normalizado
                    })
            
            # Remover duplicatas (picos muito pr칩ximos)
            climax_moments = self._merge_overlapping_moments(climax_moments)
            
            logger.info(f"Encontrados {len(climax_moments)} picos ac칰sticos")
            return climax_moments
            
        except Exception as e:
            logger.error(f"Erro na an치lise ac칰stica: {e}")
            return []
    
    def _merge_overlapping_moments(self, moments: List[Dict], min_gap: float = 10.0) -> List[Dict]:
        """
        Mescla momentos que est칚o muito pr칩ximos um do outro
        
        Args:
            moments: Lista de momentos
            min_gap: Dist칙ncia m칤nima entre momentos (segundos)
            
        Returns:
            Lista de momentos mesclados
        """
        if not moments:
            return []
        
        # Ordenar por tempo de in칤cio
        moments = sorted(moments, key=lambda x: x['start'])
        
        merged = [moments[0]]
        
        for current in moments[1:]:
            last = merged[-1]
            
            # Se os momentos est칚o pr칩ximos, mesclar
            if current['start'] - last['end'] < min_gap:
                last['end'] = max(last['end'], current['end'])
                # Manter o maior score
                if 'score' in current and 'score' in last:
                    last['score'] = max(last['score'], current['score'])
            else:
                merged.append(current)
        
        return merged
    
    def combine_analyses(
        self, 
        semantic_moments: List[Dict], 
        acoustic_moments: List[Dict]
    ) -> List[Dict]:
        """
        Combina an치lises sem칙ntica e ac칰stica, priorizando momentos que aparecem em ambas
        
        Args:
            semantic_moments: Momentos encontrados na an치lise de texto
            acoustic_moments: Momentos encontrados na an치lise de 치udio
            
        Returns:
            Lista unificada e ranqueada de momentos de cl칤max
        """
        combined = []
        
        # Adicionar todos os momentos sem칙nticos (alta prioridade)
        for sem_moment in semantic_moments:
            moment = sem_moment.copy()
            moment['priority'] = 'high'
            
            # Verificar se h치 sobreposi칞칚o com picos ac칰sticos
            for ac_moment in acoustic_moments:
                if self._moments_overlap(sem_moment, ac_moment):
                    moment['priority'] = 'very_high'  # Combina칞칚o perfeita!
                    moment['acoustic_boost'] = ac_moment.get('peak_db', 0)
                    logger.info(f"游댠 CL칈MAX COMBINADO em {moment['start']:.2f}s: '{moment.get('keyword', '')}'")
                    break
            
            combined.append(moment)
        
        # Adicionar momentos ac칰sticos que n칚o sobrep칫em com sem칙nticos
        for ac_moment in acoustic_moments:
            has_overlap = any(self._moments_overlap(ac_moment, sem) for sem in semantic_moments)
            if not has_overlap:
                moment = ac_moment.copy()
                moment['priority'] = 'medium'
                combined.append(moment)
        
        # Ordenar por prioridade e score
        priority_order = {'very_high': 3, 'high': 2, 'medium': 1}
        combined.sort(
            key=lambda x: (priority_order.get(x.get('priority', 'medium'), 0), x.get('score', 0)),
            reverse=True
        )
        
        return combined
    
    def _moments_overlap(self, moment1: Dict, moment2: Dict) -> bool:
        """Verifica se dois momentos se sobrep칫em no tempo"""
        return not (moment1['end'] < moment2['start'] or moment2['end'] < moment1['start'])
    
    def create_cut_points(self, climax_moments: List[Dict]) -> List[Dict]:
        """
        Converte momentos de cl칤max em pontos de corte com dura칞칚o adequada
        
        Args:
            climax_moments: Lista de momentos identificados
            
        Returns:
            Lista de pontos de corte prontos para extra칞칚o:
            [
                {
                    'start': 120.0,
                    'end': 180.0,
                    'duration': 60,
                    'reason': 'keyword: milh칚o',
                    'priority': 'very_high'
                },
                ...
            ]
        """
        cut_points = []
        
        for moment in climax_moments:
            # Aplicar pre-roll e post-roll
            start = max(0, moment['start'] - self.pre_roll)
            end = moment['end'] + self.post_roll
            duration = end - start
            
            # Ajustar para respeitar dura칞칚o m칤nima/m치xima
            if duration < self.cut_duration_min:
                # Expandir simetricamente
                expansion = (self.cut_duration_min - duration) / 2
                start = max(0, start - expansion)
                end = end + expansion
                duration = end - start
            
            if duration > self.cut_duration_max:
                # Truncar simetricamente ao redor do ponto de interesse
                center = (moment['start'] + moment['end']) / 2
                start = center - (self.cut_duration_max / 2)
                end = center + (self.cut_duration_max / 2)
                duration = self.cut_duration_max
            
            # Criar descri칞칚o do motivo do corte
            reason = moment.get('keyword', moment.get('type', 'unknown'))
            if moment.get('type') == 'semantic':
                reason = f"keyword: {moment.get('keyword', '')}"
            elif moment.get('type') == 'acoustic':
                reason = f"volume peak: {moment.get('peak_db', 0):.1f}dB"
            
            cut_points.append({
                'start': float(start),
                'end': float(end),
                'duration': float(duration),
                'reason': reason,
                'priority': moment.get('priority', 'medium'),
                'text': moment.get('text', '')
            })
        
        logger.info(f"Criados {len(cut_points)} pontos de corte")
        return cut_points


# Teste do m칩dulo
if __name__ == "__main__":
    # Exemplo de configura칞칚o
    analyzer = ClimaxAnalyzer(
        keywords_climax=["milh칚o", "segredo", "aten칞칚o", "incr칤vel"],
        keywords_ignore=["patrocinador", "inscreva-se", "an칰ncio"],
        min_volume_db=-10.0,
        cut_duration_min=30,
        cut_duration_max=90
    )
    
    print("Analisador de cl칤max configurado!")
    print(f"Palavras-chave: {analyzer.keywords_climax}")
    print(f"Volume m칤nimo: {analyzer.min_volume_db}dB")
